{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a62e27c-fba0-428f-a863-ebafefc7baf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.linalg import svd\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af64479-c20e-4538-979a-3f68397cb11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_digits(X, title):\n",
    "    \"\"\"Small helper function to plot 100 digits.\"\"\"\n",
    "    fig, axs = plt.subplots(nrows=10, ncols=10, figsize=(8, 8))\n",
    "    for img, ax in zip(X, axs.ravel()):\n",
    "        ax.imshow(img.reshape((16, 16)), cmap=\"Greys\")\n",
    "        ax.axis(\"off\")\n",
    "    fig.suptitle(title, fontsize=24)\n",
    "\n",
    "def SSIM_Batch(X, X_true):\n",
    "    m, _ = X.shape\n",
    "    ssim_val = 0\n",
    "    for i in range(m):\n",
    "        ns = X[i].reshape((16, 16))\n",
    "        gt = X_true[i].reshape((16, 16))\n",
    "\n",
    "        ssim_val += ssim(ns, gt, data_range=1.)\n",
    "\n",
    "    return ssim_val / m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdde160-4425-44e0-a814-d99b1e251d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = fetch_openml(data_id=41082, as_frame=False, return_X_y=True)\n",
    "X = MinMaxScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2836c76-0f76-4404-a4e7-e3ff8104c4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, random_state=0, train_size=1_000, test_size=100\n",
    ")\n",
    "\n",
    "rng = np.random.RandomState(0)\n",
    "noise = rng.normal(scale=0.25, size=X_test.shape)\n",
    "X_test_noisy = X_test + noise\n",
    "\n",
    "noise = rng.normal(scale=0.25, size=X_train.shape)\n",
    "X_train_noisy = X_train + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ddd25c-6f41-4a85-8686-794295f0c4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_digits(X_test, \"Uncorrupted test images\")\n",
    "plot_digits(\n",
    "    X_test_noisy, f\"Noisy test images\\nMSE: {np.mean((X_test - X_test_noisy) ** 2):.2f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3dcb49a-30bb-416f-87a3-3931ebabeff8",
   "metadata": {},
   "source": [
    "# PCA - Principal Component Analysis\n",
    "\n",
    "Given a matrix of data $X$, we will perform PCA to reduce the dimension of $X$ and then transform back in hopes that we remove the noise, which is usually related to the lower valued singular values, while still keeping the relevant information usually related to the higher eigenvalues. We do this by first making $X$ have zero mean, transforming it to a lower dimension, and then transforming it back to the original dimension only keeping the largest *Principal Components* which are the singular values of normalized $X$.\n",
    "\n",
    "1. First, normalize $X$ with the column mean of $X$, denoted as $\\mu_X$, to get $\\hat{X}$:\n",
    "\n",
    "$$\\hat{X} = X - \\mu_X$$\n",
    "\n",
    "\n",
    "2. Perform the SVD of $\\hat{X}$:\n",
    "$$\\hat{X} = U\\Sigma W^T$$\n",
    "\n",
    "3. Transform $\\hat{X}$ to $Z_k$, where $Z_k$ is the lower dimensional representation of $\\hat{X}$ using $k$ of the principal components (right singular vectors) of $\\hat{X}$:\n",
    "$$Z_k = \\hat{X}W_k$$\n",
    "\n",
    "4. We can transform back to the original dimension while loosing lower level information to get $X_k$:\n",
    "$$X_k = Z_kW_k^T$$\n",
    "\n",
    "We can see the error of $X$ against $X_k$ using the MSE score defined as $||e_k||^2_2$, where $e_k = X - X_k$ and note that as $k$ increases, $e_k$ will decrease.\n",
    "\n",
    "**NOTE** The sign corresponding to the vectors in $U$ and $W$ can be different depending on implementation, but will cancel out when multiplied to get $X$ back."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8622aaae-9e58-43a9-8dd4-005a32f9c611",
   "metadata": {},
   "source": [
    "## Singular Value Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a746ee-ff07-4d91-95f3-b9ec1b5f0cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_train_means = np.mean(X_train_noisy, axis=0)\n",
    "col_test_means = np.mean(X_test_noisy, axis=0)\n",
    "\n",
    "X_train_hat = X_train_noisy - col_train_means\n",
    "X_test_hat = X_test_noisy - col_test_means\n",
    "\n",
    "U_train, s_train, W_train = svd(X_train_hat, full_matrices=True)\n",
    "U_test, s_test, W_test = svd(X_test_hat, full_matrices=True)\n",
    "\n",
    "S_train = np.zeros_like(X_train_hat)\n",
    "S_train[:len(s_train), :len(s_train)] = np.diag(s_train)\n",
    "\n",
    "S_test = np.zeros_like(X_test_hat)\n",
    "S_test[:len(s_test), :len(s_test)] = np.diag(s_test)\n",
    "\n",
    "print('X_train_hat == U_train S_train W_train: ', np.allclose(X_train_hat, np.matmul(np.matmul(U_train, S_train), W_train)))\n",
    "print('X_test_hat == U_test S_test W_test: \\t', np.allclose(X_test_hat, np.matmul(np.matmul(U_test, S_test), W_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0516bb20-9580-4630-b957-24e9e8a1399c",
   "metadata": {},
   "source": [
    "## PCA - All Singular Values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d64a582-3cb9-42fe-88c5-b09cc71bb87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=256)\n",
    "pca.fit(X_train_noisy)\n",
    "\n",
    "Z_train_noisy = pca.transform(X_train_noisy)\n",
    "\n",
    "print('Z_train_noisy == X_train_hat W_train: \\t\\t', \n",
    "      np.allclose(abs(Z_train_noisy), abs(np.matmul(X_train_hat, W_train.T))))\n",
    "print('Z_train_noisy == X_train_hat pca.components_.T: ', \n",
    "      np.allclose(Z_train_noisy, np.matmul(X_train_hat, pca.components_.T)))\n",
    "print('Z_train_noisy == U_train S_train: \\t\\t', \n",
    "      np.allclose(abs(Z_train_noisy), abs(np.matmul(U_train, S_train))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12334934-7453-440c-8c01-6ccd077a13aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.matmul(X_train_hat, W_train.T)\n",
    "X_train_back = pca.inverse_transform(Z_train_noisy)\n",
    "\n",
    "print('X_train_noisy == X_train_back: \\t\\t\\t\\t', \n",
    "      np.allclose(X_train_noisy, X_train_back))\n",
    "print('X_train_noisy == (X_train_hat W_train.T) W_train: \\t', \n",
    "      np.allclose(X_train_hat, np.matmul(Z, W_train)))\n",
    "print('X_train_noisy == Z_train_noisy, pca.components_: \\t', \n",
    "      np.allclose(X_train_hat, np.matmul(Z_train_noisy, pca.components_)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a44a0a-cbdd-4195-be44-151389182b85",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fa89e1-3423-4792-a462-f2e519676cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_test_noisy = pca.transform(X_test_noisy)\n",
    "X_test_pca = pca.inverse_transform(Z_test_noisy)\n",
    "\n",
    "print('Z_test_noisy == (X_test_noisy - col_train_means) pca.components_.T: ', \n",
    "      np.allclose(Z_test_noisy, np.dot(X_test_noisy - col_train_means, pca.components_.T)))\n",
    "\n",
    "print()\n",
    "print('MSE Error: ', np.mean((X_test_pca - X_test) ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd8a1b6-2d2c-46db-b53e-79e619d183a6",
   "metadata": {},
   "source": [
    "## PCA - 32 Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e6cc00-77d6-4ba5-8b54-6a2b669e9918",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 32\n",
    "pca = PCA(n_components=k)\n",
    "\n",
    "pca.fit(X_train_noisy)\n",
    "\n",
    "Z_test_noisy = pca.transform(X_test_noisy)\n",
    "X_test_pca = pca.inverse_transform(Z_test_noisy)\n",
    "print('MSE Error: ', np.mean((X_test_pca - X_test) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb3460f-b75e-4295-93ee-c4ecad1568d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_digits(X_test, \"Uncorrupted test images\")\n",
    "plot_digits(\n",
    "    X_test_noisy, f\"Noisy test images\\nMSE: {np.mean((X_test - X_test_noisy) ** 2):.3f}\"\n",
    ")\n",
    "plot_digits(\n",
    "    X_test_pca,\n",
    "    f\"PCA reconstruction, k = {k}, \\nMSE: {np.mean((X_test - X_test_pca) ** 2):.3f}\".format(k=k),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1052de-10f6-4381-b2ef-2123ee827e5d",
   "metadata": {},
   "source": [
    "## Find the best $k$ value for this denoising method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea63efeb-822b-4f4e-b519-8fd00e9be10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_vals = np.arange(1, 256 + 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d89b13d-ae64-4e6f-82f6-d1d1ee0d1ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE = []\n",
    "SSIM_array = []\n",
    "MSE_max = 1e4\n",
    "MSE_index = -1\n",
    "for index, k in enumerate(k_vals):\n",
    "    pca = PCA(n_components=k)\n",
    "    pca.fit(X_train_noisy)\n",
    "    \n",
    "    Z_test_noisy = pca.transform(X_test_noisy)\n",
    "    X_test_pca = pca.inverse_transform(Z_test_noisy)\n",
    "    MSE_val = np.mean((X_test_pca - X_test) ** 2)\n",
    "    SSIM_val = SSIM_Batch(X_test, X_test_pca)\n",
    "    MSE.append(MSE_val)\n",
    "    SSIM_array.append(SSIM_val)\n",
    "\n",
    "    if MSE_max > MSE_val:\n",
    "        MSE_max = MSE_val\n",
    "        MSE_index = index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0e3d9c-79ce-41f6-857b-5d9733b7b423",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "fig.add_trace(go.Scatter(x=k_vals, y=MSE, name='MSE'), secondary_y=False)\n",
    "# fig.add_trace(go.Scatter(x=k_vals, y=SSIM_array, name='SSIM'), secondary_y=True)\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title='Principal Components',\n",
    "    yaxis_title='Loss',\n",
    "    width=1000,  # Set width of the graph\n",
    "    height=400  # Set height of the graph\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a105496c-7d18-4e14-b469-cb9d8e027679",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = k_vals[MSE_index]\n",
    "pca = PCA(n_components=k)\n",
    "\n",
    "pca.fit(X_train_noisy)\n",
    "\n",
    "Z_test_noisy = pca.transform(X_test_noisy)\n",
    "X_test_pca = pca.inverse_transform(Z_test_noisy)\n",
    "print('MSE Error: ', np.mean((X_test_pca - X_test) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9654d8ac-3ee1-411f-9c44-31ee3edae46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_digits_plotly(X):\n",
    "    \"\"\"Small helper function to plot 64 digits using plotly.\"\"\"\n",
    "    # Create subplot grid\n",
    "    fig = make_subplots(rows=8, cols=8)\n",
    "    \n",
    "    # Add each image as a heatmap\n",
    "    for idx, img in enumerate(X[:64]):\n",
    "        row = idx // 8 + 1\n",
    "        col = idx % 8 + 1\n",
    "        \n",
    "        # Reshape image and create heatmap\n",
    "        img_reshaped = img.reshape((16, 16))\n",
    "        fig.add_trace(\n",
    "            go.Heatmap(z=img_reshaped, \n",
    "                      colorscale='Greys',\n",
    "                      showscale=False),\n",
    "            row=row, col=col\n",
    "        )\n",
    "        \n",
    "        # Remove axes for each subplot\n",
    "        fig.update_xaxes(showticklabels=False, showgrid=False, row=row, col=col)\n",
    "        fig.update_yaxes(autorange=\"reversed\", showticklabels=False, showgrid=False, row=row, col=col)\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        width=800,\n",
    "        height=800,\n",
    "        showlegend=False,\n",
    "        margin=dict(t=0, l=0, r=0, b=0)\n",
    "    )\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ba1ec8-25ab-4148-8d61-6a00167c1236",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_digits_plotly(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcae242-d1da-4fca-ad28-d3fc230b4782",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_digits_plotly(X_test_noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6dd6419-3ee1-474b-a9d4-f0aa948db3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_digits_plotly(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfdb8c0-1c24-4204-82b9-0973ae70d7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "SSIM_Batch(X_test_pca, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39887be0-c70a-435c-a489-976658dbf9d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
